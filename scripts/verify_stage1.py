#!/usr/bin/env python3
"""
LLM-UnTangle ç¬¬ä¸€éšæ®µå®Œæ•´é©—è­‰ï¼ˆåŒ…å«åŸç¬¬äºŒéšæ®µå…§å®¹ï¼‰
- åŸºç¤ç’°å¢ƒæª¢æŸ¥ï¼ˆPythonã€å¥—ä»¶ã€Dockerï¼‰
- è³‡æ–™é›†å®Œæ•´æ€§é©—è­‰
- OOD å®¹å™¨ç‹€æ…‹æª¢æŸ¥
- Untangle åŸºç·šæ¸¬è©¦çµæœ
- BCa Bootstrap çµ±è¨ˆåˆ†æ
- è«–æ–‡å¯¦é©—å®Œæ•´æ€§é©—è­‰
"""
import sys
import json
import subprocess
import time
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
RESULT = {
    'python': {},
    'packages': {},
    'docker': {},
    'datasets': {},
    'docker_configs': {},
    'ood_containers': {},
    'baseline_test': {},
    'bca_confidence': {},
    'paper_requirements': {},
    'summary': {}
}
PASS, FAIL, WARN = 'PASS', 'FAIL', 'WARN'

def record(section, key, status, detail=""):
    RESULT[section][key] = {'status': status, 'detail': detail}
    return status == PASS

def shell(cmd):
    try:
        out = subprocess.run(cmd, capture_output=True, text=True, shell=True, cwd=ROOT)
        return out.returncode, out.stdout.strip() or out.stderr.strip()
    except Exception as e:
        return 1, str(e)

# ========== åŸºç¤ç’°å¢ƒæª¢æŸ¥ ==========
def check_python_environment():
    """æª¢æŸ¥ Python ç’°å¢ƒå’ŒåŸºç¤å¥—ä»¶"""
    record('python', 'version', PASS, sys.version)

    # åŸºç¤å¥—ä»¶
    for mod, name in [('pandas','pandas'), ('numpy','numpy'), ('sklearn','scikit-learn'), 
                      ('faiss','faiss-cpu'), ('statsmodels','statsmodels'), ('mapie','mapie')]:
        try:
            __import__(mod)
            record('packages', name, PASS)
        except Exception as e:
            record('packages', name, FAIL, str(e))

    # sentence-transformers å¯ç”¨æ€§æª¢æŸ¥ï¼ˆå¯¬é¬†ï¼‰
    try:
        import importlib
        st = importlib.import_module('sentence_transformers')
        record('packages', 'sentence-transformers', PASS)
    except Exception as e:
        hint = (
            'è‹¥ç‚º Windows DLL éŒ¯èª¤ï¼Œè«‹å…ˆåŸ·è¡Œä¸€éµä¿®å¾©:\n'
            '  python scripts\\fix_sentence_transformers_windows.py\n'
            'æˆ–æ‰‹å‹•å®‰è£ CPU ç‰ˆ torchï¼š\n'
            '  pip uninstall -y torch torchvision torchaudio\n'
            '  pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio\n'
        )
        record('packages', 'sentence-transformers', WARN, f"{e}\n{hint}")

def check_docker():
    """æª¢æŸ¥ Docker ç’°å¢ƒ"""
    code, out = shell('docker --version')
    record('docker', 'docker', PASS if code == 0 else FAIL, out)
    code, out = shell('docker compose version')
    record('docker', 'compose', PASS if code == 0 else FAIL, out)

def check_datasets():
    """æª¢æŸ¥è³‡æ–™é›†å®Œæ•´æ€§"""
    # combinations.json
    combo_path = ROOT / 'data' / 'combinations.json'
    if combo_path.exists():
        try:
            combos = json.loads(combo_path.read_text(encoding='utf-8'))
            record('datasets', 'combinations.json', PASS if 250 <= len(combos) <= 300 else WARN, f"count={len(combos)}")
        except Exception as e:
            record('datasets', 'combinations.json', FAIL, str(e))
    else:
        record('datasets', 'combinations.json', FAIL, 'missing data/combinations.json')

    # è³‡æ–™åˆ†å‰²æª”æ¡ˆ
    proc = ROOT / 'data' / 'processed'
    missing = [f for f in ['train.csv','val.csv','test.csv'] if not (proc / f).exists()]
    if missing:
        record('datasets', 'splits', FAIL, f"missing: {missing}")
    else:
        def cnt(p):
            try:
                return sum(1 for _ in open(p, 'r', encoding='utf-8')) - 1
            except Exception:
                return -1
        n_train, n_val, n_test = cnt(proc/'train.csv'), cnt(proc/'val.csv'), cnt(proc/'test.csv')
        total = n_train + n_val + n_test
        if total > 0:
            r_train, r_val, r_test = n_train/total, n_val/total, n_test/total
            ok = abs(r_train-0.6)<=0.1 and abs(r_val-0.2)<=0.1 and abs(r_test-0.2)<=0.1
            record('datasets', 'split_ratio', PASS if ok else WARN, 
                   f"train={n_train}({r_train:.2f}), val={n_val}({r_val:.2f}), test={n_test}({r_test:.2f})")
        else:
            record('datasets', 'split_ratio', FAIL, 'empty files')

    # OOD è³‡æ–™é›†
    ood_path = ROOT / 'data' / 'ood' / 'ood_combinations.json'
    if ood_path.exists():
        try:
            ood = json.loads(ood_path.read_text(encoding='utf-8'))
            record('datasets', 'ood', PASS if len(ood) >= 50 else FAIL, f"count={len(ood)}")
        except Exception as e:
            record('datasets', 'ood', FAIL, str(e))
    else:
        record('datasets', 'ood', FAIL, 'missing data/ood/ood_combinations.json')

def check_docker_configs():
    """æª¢æŸ¥ Docker çµ„æ…‹æª”æ¡ˆ"""
    conf_dir = ROOT / 'docker_configs'
    if conf_dir.exists():
        count = len(list(conf_dir.glob('compose_*.yml')))
        record('docker_configs', 'compose_files', PASS if count >= 1 else FAIL, f"count={count}")
    else:
        record('docker_configs', 'compose_files', FAIL, 'missing docker_configs dir')

# ========== å¯¦é©—ç’°å¢ƒæª¢æŸ¥ ==========
def check_ood_containers():
    """æª¢æŸ¥ OOD å®¹å™¨ç‹€æ…‹"""
    ood_status_path = ROOT / 'results' / 'ood_containers_status.json'
    if not ood_status_path.exists():
        record('ood_containers', 'status_file', WARN, 
               'ç¼ºå°‘ ood_containers_status.jsonï¼Œè«‹åŸ·è¡Œ start_ood_containers.py')
        return False
    
    try:
        data = json.loads(ood_status_path.read_text(encoding='utf-8'))
        running_count = data.get('ood_services_running', 0)
        meets_req = data.get('paper_requirements_met', False)
        
        if running_count == 0:
            record('ood_containers', 'services', FAIL, 'no OOD services running')
            return False
        
        detail = f"running={running_count}, requirements_met={meets_req}"
        status = PASS if meets_req else WARN
        record('ood_containers', 'requirements', status, detail)
        return meets_req
        
    except Exception as e:
        record('ood_containers', 'parse_error', FAIL, str(e))
        return False

def check_baseline_test():
    """æª¢æŸ¥åŸºç·šæ¸¬è©¦çµæœ"""
    baseline_path = ROOT / 'results' / 'untangle_baseline_results.json'
    if not baseline_path.exists():
        record('baseline_test', 'results_file', WARN, 
               'ç¼ºå°‘ untangle_baseline_results.jsonï¼Œè«‹åŸ·è¡Œ run_untangle_baseline.py')
        return False
    
    try:
        data = json.loads(baseline_path.read_text(encoding='utf-8'))
        test_samples = data.get('test_samples', 0)
        overall_acc = data.get('overall_accuracy', {})
        detailed_results = data.get('detailed_results', [])
        
        if test_samples == 0:
            record('baseline_test', 'samples', FAIL, 'no test samples processed')
            return False
        
        # æª¢æŸ¥ L3 æº–ç¢ºç‡
        l3_acc = overall_acc.get('l3', -1)
        if not (0 <= l3_acc <= 1):
            record('baseline_test', 'validity', FAIL, f'invalid L3 accuracy: {l3_acc}')
            return False
        
        # æª¢æŸ¥è©³ç´°çµæœï¼ˆBCa éœ€è¦ï¼‰
        if len(detailed_results) != test_samples:
            record('baseline_test', 'completeness', WARN, 
                   f'detailed_results={len(detailed_results)}, expected={test_samples}')
        
        detail = f"samples={test_samples}, L3_accuracy={l3_acc:.3f}, detailed_complete={len(detailed_results)==test_samples}"
        record('baseline_test', 'results', PASS, detail)
        return True
        
    except Exception as e:
        record('baseline_test', 'parse_error', FAIL, str(e))
        return False

def check_bca_confidence():
    """æª¢æŸ¥ BCa çµ±è¨ˆåˆ†æ"""
    bca_path = ROOT / 'results' / 'bca_confidence_intervals.json'
    if not bca_path.exists():
        record('bca_confidence', 'results_file', WARN, 
               'ç¼ºå°‘ bca_confidence_intervals.jsonï¼Œè«‹åŸ·è¡Œ calculate_bca_confidence.py')
        return False
    
    try:
        data = json.loads(bca_path.read_text(encoding='utf-8'))
        l3_analysis = data.get('l3_accuracy_analysis', {})
        
        if not l3_analysis:
            record('bca_confidence', 'analysis', FAIL, 'no L3 analysis found')
            return False
        
        # æª¢æŸ¥é—œéµçµ±è¨ˆæŒ‡æ¨™
        lower = l3_analysis.get('lower_bound', -1)
        upper = l3_analysis.get('upper_bound', -1)
        bootstrap_samples = l3_analysis.get('bootstrap_samples', 0)
        
        if not (0 <= lower <= upper <= 1):
            record('bca_confidence', 'validity', FAIL, 
                   f'invalid confidence interval: [{lower:.3f}, {upper:.3f}]')
            return False
        
        if bootstrap_samples < 1000:
            record('bca_confidence', 'bootstrap_quality', WARN, 
                   f'low bootstrap samples: {bootstrap_samples}')
        
        ci_width = upper - lower
        detail = f"CI=[{lower:.3f}, {upper:.3f}], width={ci_width:.3f}, bootstrap_n={bootstrap_samples}"
        record('bca_confidence', 'statistics', PASS, detail)
        return True
        
    except Exception as e:
        record('bca_confidence', 'parse_error', FAIL, str(e))
        return False

def check_paper_requirements():
    """æª¢æŸ¥è«–æ–‡å¯¦é©—è¦æ±‚å®Œæ•´æ€§"""
    ood_ok = 'ood_containers' in RESULT and any(
        item['status'] == PASS for item in RESULT['ood_containers'].values()
    )
    baseline_ok = 'baseline_test' in RESULT and any(
        item['status'] == PASS for item in RESULT['baseline_test'].values()
    )
    bca_ok = 'bca_confidence' in RESULT and any(
        item['status'] == PASS for item in RESULT['bca_confidence'].values()
    )
    
    # OOD æª¢æ¸¬å¯¦é©—
    record('paper_requirements', 'ood_detection', PASS if ood_ok else WARN, 
           'Out-of-Distribution æª¢æ¸¬å¯¦é©—ç’°å¢ƒ')
    
    # åŸºç·šæ¯”è¼ƒ
    record('paper_requirements', 'baseline_comparison', PASS if baseline_ok else WARN,
           'Untangle vs LLM-UnTangle åŸºç·šæ¯”è¼ƒ')
    
    # çµ±è¨ˆé©—è­‰
    record('paper_requirements', 'statistical_validation', PASS if bca_ok else WARN,
           'BCa Bootstrap ç½®ä¿¡å€é–“çµ±è¨ˆé©—è­‰')
    
    # å®Œæ•´å·¥ä½œæµç¨‹
    all_complete = ood_ok and baseline_ok and bca_ok
    record('paper_requirements', 'complete_pipeline', PASS if all_complete else WARN,
           f'å®Œæ•´è«–æ–‡å¯¦é©—ç®¡ç·š (OOD={ood_ok}, Baseline={baseline_ok}, Stats={bca_ok})')
    
    return all_complete

def main():
    print('ğŸ§ª LLM-UnTangle ç¬¬ä¸€éšæ®µå®Œæ•´é©—è­‰')
    print('=' * 60)
    
    # åŸºç¤ç’°å¢ƒæª¢æŸ¥
    print('ğŸ“‹ åŸºç¤ç’°å¢ƒæª¢æŸ¥...')
    check_python_environment()
    check_docker()
    check_datasets()
    check_docker_configs()
    
    # å¯¦é©—ç’°å¢ƒæª¢æŸ¥
    print('ğŸ”¬ å¯¦é©—ç’°å¢ƒæª¢æŸ¥...')
    ok_ood = check_ood_containers()
    ok_baseline = check_baseline_test()
    ok_bca = check_bca_confidence()
    ok_paper = check_paper_requirements()
    
    # å°‡ sentence-transformers çš„ WARN è¦–ç‚ºå¯æ”¾è¡Œï¼ˆä¸é˜»æ“‹ overallï¼‰
    all_ok = True
    for section, items in RESULT.items():
        if section in ['summary', 'paper_requirements']:
            continue
        for key, val in items.items():
            if val['status'] == FAIL:
                all_ok = False

    RESULT['summary'] = {
        'overall': PASS if all_ok else FAIL,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'paper_ready': ok_paper
    }

    # ä¿å­˜çµæœ
    out_dir = ROOT / 'results'
    out_dir.mkdir(parents=True, exist_ok=True)
    (out_dir / 'stage1_complete_checklist.json').write_text(
        json.dumps(RESULT, indent=2, ensure_ascii=False), encoding='utf-8'
    )

    # è¼¸å‡ºå ±å‘Š
    print('\nğŸ“‹ é©—è­‰æ‘˜è¦:')
    for section, items in RESULT.items():
        if section == 'summary':
            continue
        print(f"\n{section.upper().replace('_', ' ')}:")
        for key, val in items.items():
            status_icon = 'âœ…' if val['status'] == PASS else 'âš ï¸' if val['status'] == WARN else 'âŒ'
            print(f"  {status_icon} {key}: {val.get('detail','')}")

    print(f"\nğŸ¯ ç¸½é«”ç‹€æ…‹: {RESULT['summary']['overall']}")
    
    if RESULT['summary']['paper_ready']:
        print('ğŸ‰ è«–æ–‡å¯¦é©—ç’°å¢ƒå®Œæ•´ï¼Œå¯é€²è¡Œæ‰€æœ‰åˆ†æ!')
    else:
        print('âš ï¸ éƒ¨åˆ†å¯¦é©—çµ„ä»¶æœªå®Œæˆï¼Œå»ºè­°åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤å®Œæˆè¨­å®š:')
        if not ok_ood:
            print('   python scripts/start_ood_containers.py')
        if not ok_baseline:
            print('   python scripts/run_untangle_baseline.py')
        if not ok_bca:
            print('   python scripts/calculate_bca_confidence.py')

    print(f'\nğŸ“„ è©³ç´°çµæœå·²ä¿å­˜åˆ°: results/stage1_complete_checklist.json')

    sys.exit(0 if RESULT['summary']['overall'] == PASS else 1)

if __name__ == '__main__':
    main()