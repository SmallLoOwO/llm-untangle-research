#!/usr/bin/env python3
"""
BCa Bootstrap ç½®ä¿¡å€é–“è¨ˆç®—ï¼ˆä¿®æ­£ç‰ˆï¼‰
- ä½¿ç”¨å®Œæ•´ detailed_results è€Œéæˆªæ–·ç‰ˆæœ¬
- å¢åŠ çµ±è¨ˆæœ‰æ•ˆæ€§æª¢æŸ¥
- è¼¸å‡ºæ›´è©³ç´°çš„çµ±è¨ˆå ±å‘Š
"""
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
from scipy import stats
import time

ROOT = Path(__file__).resolve().parents[1]
BASELINE_RESULTS_PATH = ROOT / 'results' / 'untangle_baseline_results.json'
RESULTS_DIR = ROOT / 'results'

def load_baseline_results():
    if not BASELINE_RESULTS_PATH.exists():
        raise FileNotFoundError(f'æ‰¾ä¸åˆ° {BASELINE_RESULTS_PATH}ï¼Œè«‹å…ˆåŸ·è¡Œ run_untangle_baseline.py')
    return json.loads(BASELINE_RESULTS_PATH.read_text(encoding='utf-8'))

def jackknife_bias_acceleration(data, statistic_func):
    """è¨ˆç®— Jackknife åå·®æ ¡æ­£èˆ‡åŠ é€Ÿåƒæ•¸"""
    n = len(data)
    if n < 3:
        return 0.0, 0.0  # æ¨£æœ¬å¤ªå°‘ï¼Œè¿”å›é è¨­å€¼
        
    theta_hat = statistic_func(data)
    
    # Jackknife ä¼°è¨ˆ
    jackknife_estimates = []
    for i in range(n):
        jackknife_sample = np.concatenate([data[:i], data[i+1:]])
        jackknife_estimates.append(statistic_func(jackknife_sample))
    
    jackknife_estimates = np.array(jackknife_estimates)
    theta_dot = np.mean(jackknife_estimates)
    
    # åå·®æ ¡æ­£ z0
    proportion = np.sum(jackknife_estimates < theta_hat) / n
    z0 = stats.norm.ppf(max(0.001, min(0.999, proportion)))
    
    # åŠ é€Ÿåƒæ•¸ a
    numerator = np.sum((theta_dot - jackknife_estimates) ** 3)
    denominator = 6 * (np.sum((theta_dot - jackknife_estimates) ** 2) ** 1.5)
    a = numerator / denominator if abs(denominator) > 1e-10 else 0
    
    return z0, a

def bca_bootstrap(data, statistic_func, n_bootstrap=10000, alpha=0.05):
    """BCa Bootstrap ç½®ä¿¡å€é–“è¨ˆç®—"""
    n = len(data)
    if n < 5:
        return {'error': f'æ¨£æœ¬æ•¸å¤ªå°‘ (n={n})ï¼Œç„¡æ³•é€²è¡Œ Bootstrap åˆ†æ'}
    
    # Bootstrap é‡æŠ½æ¨£
    print(f'é€²è¡Œ {n_bootstrap:,} æ¬¡ Bootstrap é‡æŠ½æ¨£...')
    bootstrap_estimates = []
    
    np.random.seed(42)
    for _ in tqdm(range(n_bootstrap), desc='Bootstrap æŠ½æ¨£'):
        bootstrap_sample = np.random.choice(data, size=n, replace=True)
        bootstrap_estimates.append(statistic_func(bootstrap_sample))
    
    bootstrap_estimates = np.array(bootstrap_estimates)
    
    # è¨ˆç®— z0 èˆ‡ a
    print('è¨ˆç®— Bias-Correction èˆ‡ Acceleration åƒæ•¸...')
    z0, a = jackknife_bias_acceleration(data, statistic_func)
    
    # BCa èª¿æ•´
    z_alpha_2 = stats.norm.ppf(alpha / 2)
    z_1_alpha_2 = stats.norm.ppf(1 - alpha / 2)
    
    # é˜²æ­¢é™¤é›¶
    denom1 = 1 - a * (z0 + z_alpha_2)
    denom2 = 1 - a * (z0 + z_1_alpha_2)
    
    if abs(denom1) < 1e-10 or abs(denom2) < 1e-10:
        print('âš ï¸ BCa åƒæ•¸ç•°å¸¸ï¼Œä½¿ç”¨åŸºæœ¬ Bootstrap ç™¾åˆ†ä½æ•¸')
        alpha1, alpha2 = alpha/2, 1-alpha/2
    else:
        alpha1 = stats.norm.cdf(z0 + (z0 + z_alpha_2) / denom1)
        alpha2 = stats.norm.cdf(z0 + (z0 + z_1_alpha_2) / denom2)
        alpha1 = max(0.001, min(0.999, alpha1))
        alpha2 = max(0.001, min(0.999, alpha2))
    
    lower_bound = np.percentile(bootstrap_estimates, alpha1 * 100)
    upper_bound = np.percentile(bootstrap_estimates, alpha2 * 100)
    
    return {
        'lower_bound': float(lower_bound),
        'upper_bound': float(upper_bound),
        'bias_correction_z0': float(z0),
        'acceleration_a': float(a),
        'bootstrap_mean': float(np.mean(bootstrap_estimates)),
        'bootstrap_std': float(np.std(bootstrap_estimates)),
        'alpha1': float(alpha1),
        'alpha2': float(alpha2),
        'original_estimate': float(statistic_func(data))
    }

def calculate_confidence_intervals():
    print('ğŸ“Š BCa Bootstrap ç½®ä¿¡å€é–“è¨ˆç®—ï¼ˆä¿®æ­£ç‰ˆï¼‰')
    print('=' * 50)
    
    baseline_data = load_baseline_results()
    detailed_results = baseline_data.get('detailed_results', [])
    
    if not detailed_results:
        print('âŒ åŸºç·šçµæœä¸­ç„¡è©³ç´°æ•¸æ“šï¼Œè«‹é‡æ–°åŸ·è¡Œ run_untangle_baseline.py')
        return None
    
    print(f'è¼‰å…¥ {len(detailed_results)} å€‹åŸºç·šæ¸¬è©¦çµæœ')
    
    confidence_results = {}
    
    for layer in ['l1', 'l2', 'l3']:
        print(f'\nè¨ˆç®— {layer.upper()} å±¤ BCa ç½®ä¿¡å€é–“...')
        
        # æå–è©²å±¤çš„æº–ç¢ºç‡æ•¸æ“š
        layer_accuracy = [r['accuracy'][layer] for r in detailed_results]
        accuracy_array = np.array(layer_accuracy, dtype=float)
        
        if len(accuracy_array) < 5:
            print(f'âš ï¸ {layer} æ¨£æœ¬æ•¸ä¸è¶³ ({len(accuracy_array)})ï¼Œè·³é')
            continue
        
        # å®šç¾©çµ±è¨ˆé‡ï¼ˆå¹³å‡æº–ç¢ºç‡ï¼‰
        def accuracy_statistic(sample):
            return np.mean(sample)
        
        # è¨ˆç®— BCa ç½®ä¿¡å€é–“
        bca_result = bca_bootstrap(accuracy_array, accuracy_statistic, n_bootstrap=10000, alpha=0.05)
        
        if 'error' in bca_result:
            print(f'âŒ {layer} BCa è¨ˆç®—å¤±æ•—: {bca_result["error"]}')
            continue
        
        confidence_results[layer] = bca_result
        
        print(f'{layer.upper()} æº–ç¢ºç‡: {bca_result["original_estimate"]:.3f}')
        print(f'Bootstrap å¹³å‡: {bca_result["bootstrap_mean"]:.3f} Â± {bca_result["bootstrap_std"]:.3f}')
        print(f'95% BCa ç½®ä¿¡å€é–“: [{bca_result["lower_bound"]:.3f}, {bca_result["upper_bound"]:.3f}]')
    
    if not confidence_results:
        print('âŒ ç„¡æ³•è¨ˆç®—ä»»ä½•å±¤çš„ç½®ä¿¡å€é–“')
        return None
    
    # ä¿å­˜çµæœ
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    output = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'method': 'BCa Bootstrap',
        'n_bootstrap': 10000,
        'confidence_level': 0.95,
        'baseline_method': 'Untangle Enhanced',
        'test_samples': len(detailed_results),
        'confidence_intervals': confidence_results
    }
    
    output_path = RESULTS_DIR / 'bca_confidence_intervals.json'
    output_path.write_text(json.dumps(output, indent=2, ensure_ascii=False), encoding='utf-8')
    
    print(f'\nâœ“ BCa ç½®ä¿¡å€é–“è¨ˆç®—å®Œæˆï¼Œçµæœå·²ä¿å­˜åˆ° {output_path}')
    return confidence_results

if __name__ == '__main__':
    calculate_confidence_intervals()