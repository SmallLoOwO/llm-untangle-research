#!/usr/bin/env python3
"""
æ‰¹æ¬¡å•Ÿå‹• 10 å®¹å™¨é€²è¡Œ Untangle åŸºç·šæ¸¬è©¦ï¼ˆsubprocess ç‰ˆæœ¬ï¼Œç„¡éœ€ docker å¥—ä»¶ï¼‰
- è§£æ±ºåŸæ¸¬è©¦ 250/250 é€£æ¥å¤±æ•—çš„å•é¡Œ
- åˆ†æ‰¹å•Ÿå‹•ã€å¥åº·æª¢æŸ¥ã€æ¸¬è©¦å¾Œç«‹å³å›æ”¶æ¸…ç†
- é©ç”¨æ–¼è³‡æºå—é™ç’°å¢ƒï¼Œé¿å…åŒæ™‚é–‹å•Ÿéå¤šå®¹å™¨
- å¢å¼· Tomcat/LiteSpeed/Lighttpd è­˜åˆ¥ç²¾ç¢ºåº¦
- å¢åŠ é‡è©¦æ©Ÿåˆ¶
"""
import json, time, re, requests, math, subprocess, sys
from pathlib import Path
from collections import defaultdict, Counter

ROOT = Path(__file__).resolve().parents[1]
RESULTS_DIR = ROOT / 'results'
TARGETS_PATH = RESULTS_DIR / 'baseline_targets.json'
BATCH_SIZE = 10
HTTP_TIMEOUT = 8
HEALTH_RETRIES = 15
HEALTH_SLEEP = 1.5

# è®ºæ–‡æ ‡å‡†çš„9ç§æœåŠ¡å™¨ç±»å‹æ˜ åƒé…ç½®
IMAGE_MAP = {
    # L1å±‚ (CDN/Front)
    'nginx_l1': 'nginx:1.20',
    'haproxy_l1': 'haproxy:2.4',
    'traefik_l1': 'traefik:2.5',
    
    # L2å±‚ (Proxy/Cache)
    'varnish_l2': 'varnish:7.0',
    'varnish': 'varnish:7.0',
    'squid_l2': 'ubuntu/squid:latest',
    'squid': 'ubuntu/squid:latest',
    'apache_l2': 'httpd:2.4',
    'apache': 'httpd:2.4',
    
    # L3å±‚ (App/Origin) - è®ºæ–‡é‡ç‚¹
    'tomcat': 'tomcat:9.0',
    'flask': 'llm-untangle-flask:latest',
    'express': 'llm-untangle-express:latest',
    
    # é€šç”¨å…¼å®¹
    'nginx': 'nginx:1.20'
}

# é‡å°ä¸ç©©å®šæˆ–é›£ä»¥å°±ç·’çš„æœå‹™å™¨é¡å‹æä¾›å‚™æ´æ˜ åƒ
FALLBACK_IMAGES = {
    # openlitespeed å¸¸è¦‹å•Ÿå‹•/å°å¤–é é¢å•é¡Œï¼Œå…ˆé€€å›å¸¸è¦‹å¯ç”¨æ˜ åƒé¿å…å¡æ‰¹æ¬¡
    'openlitespeed': [
        'litespeedtech/openlitespeed:1.7-lsphp81',
        'httpd:2.4-alpine',
        'nginx:alpine'
    ],
    # lighttpd æœ‰æ™‚å€™æ¢æ´»è¼ƒæ…¢æˆ–é é¢æ¬Šé™ï¼Œæä¾›å‚™æ´
    'lighttpd': [
        'sebp/lighttpd:1.4',
        'httpd:2.4-alpine'
    ],
    # tomcat å¦‚ 9/10 ç³»åˆ—ç•°å¸¸ï¼Œå›é€€è‡³å¦ä¸€å¤§ç‰ˆæœ¬
    'tomcat': [
        'tomcat:9.0',
        'tomcat:10.1-jdk17',
        'tomcat:8.5'
    ]
}

# æœå‹™å™¨å…§éƒ¨ç«¯å£å°æ‡‰
INTERNAL_PORT_MAP = {
    'tomcat': 8080,
    'flask': 5000,
    'express': 3000,
    'squid': 3128,
    'squid_l2': 3128,
    'varnish': 80,
    'varnish_l2': 80,
    'default': 80
}

# æœå‹™å°±ç·’ç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰
STARTUP_WAIT_MAP = {
    'tomcat': 15,  # Tomcat éœ€è¦è¼ƒé•·å•Ÿå‹•æ™‚é–“
    'flask': 8,    # Flask éœ€è¦ä¸­ç­‰å•Ÿå‹•æ™‚é–“
    'express': 8,  # Express éœ€è¦ä¸­ç­‰å•Ÿå‹•æ™‚é–“
    'varnish': 5,
    'varnish_l2': 5,
    'squid': 6,
    'squid_l2': 6,
    'default': 3
}

UA = {'User-Agent': 'Untangle-Fingerprinter/1.0'}

# é æ‹‰æ˜ åƒï¼Œé¿å…å†·å•Ÿä½µç™¼æ‹‰å–é€ æˆ start_failed
def pre_pull_images(batch_targets):
    imgs = set()
    for t in batch_targets:
        l3_type = t.get('expected_l3', t.get('L3', 'nginx')).lower()
        primary = IMAGE_MAP.get(l3_type, 'nginx:alpine')
        imgs.add(primary)
        for fb in FALLBACK_IMAGES.get(l3_type, []):
            imgs.add(fb)
    for image in imgs:
        try:
            subprocess.run(['docker', 'pull', image], capture_output=True, text=True, timeout=120)
        except Exception:
            pass

def load_targets():
    """è¼‰å…¥åŸºç·šæ¸¬è©¦ç›®æ¨™æ¸…å–®"""
    if not TARGETS_PATH.exists():
        raise FileNotFoundError(f'æ‰¾ä¸åˆ° {TARGETS_PATH}ï¼Œè«‹å…ˆåŸ·è¡Œ: python scripts/start_ood_containers.py')
    data = json.loads(TARGETS_PATH.read_text(encoding='utf-8'))
    return data.get('targets', [])

def get_host_port_from_url(url: str) -> int:
    """å¾ URL æå–ç«¯å£è™Ÿ"""
    m = re.search(r':(\d+)$', url.strip())
    if not m:
        raise ValueError(f'URL ç„¡æ³•è§£æåŸ : {url}')
    return int(m.group(1))

def docker_run(image: str, name: str, host_port: int, internal_port: int = 80, max_retries: int = 2) -> bool:
    """å•Ÿå‹•å®¹å™¨ï¼ŒæˆåŠŸè¿”å› Trueï¼Œå¸¶é‡è©¦æ©Ÿåˆ¶"""
    for attempt in range(max_retries):
        try:
            # å…ˆæ¸…ç†å¯èƒ½å­˜åœ¨çš„åŒåå®¹å™¨
            subprocess.run(['docker', 'rm', '-f', name], capture_output=True, check=False)
            
            cmd = [
                'docker', 'run', '-d', '--rm',
                '--name', name,
                '-p', f'{host_port}:{internal_port}',
                '--label', 'project=llm-untangle',
                '--label', 'type=baseline',
                image
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                return True
            
            # å¦‚æœå¤±æ•—ä¸”é‚„æœ‰é‡è©¦æ©Ÿæœƒï¼Œç­‰å¾…ä¸€ä¸‹
            if attempt < max_retries - 1:
                time.sleep(2)
                
        except Exception as e:
            if attempt == max_retries - 1:
                print(f'      âŒ å•Ÿå‹•å¤±æ•—: {e}')
                return False
            time.sleep(2)
    
    return False

def docker_stop(name: str, max_retries: int = 2):
    """åœæ­¢ä¸¦åˆªé™¤å®¹å™¨ï¼Œå¸¶é‡è©¦æ©Ÿåˆ¶"""
    for attempt in range(max_retries):
        try:
            subprocess.run(['docker', 'stop', name], capture_output=True, timeout=10, check=False)
            subprocess.run(['docker', 'rm', '-f', name], capture_output=True, timeout=10, check=False)
            return
        except Exception:
            if attempt < max_retries - 1:
                time.sleep(1)
            else:
                pass  # å˜—è©¦äº†æœ€å¤§æ¬¡æ•¸ï¼Œæ”¾æ£„

def wait_http_ready(url: str, server_type: str = 'default') -> bool:
    """ç­‰å¾… HTTP æœå‹™å°±ç·’ï¼Œæ ¹æ“šæœå‹™å™¨é¡å‹èª¿æ•´ç­‰å¾…æ™‚é–“"""
    # å…ˆç­‰å¾…åˆå§‹å•Ÿå‹•æ™‚é–“
    initial_wait = STARTUP_WAIT_MAP.get(server_type, STARTUP_WAIT_MAP['default'])
    time.sleep(initial_wait)
    
    # ç„¶å¾Œé€²è¡Œå¥åº·æª¢æŸ¥
    for _ in range(HEALTH_RETRIES):
        try:
            r = requests.get(url, timeout=HTTP_TIMEOUT, headers=UA, allow_redirects=True)
            # Tomcat å’Œ LiteSpeed å¯èƒ½è¿”å› 404ï¼Œä½†é€™ä»ç„¶è¡¨ç¤ºæœå‹™å°±ç·’
            if r.status_code < 500:
                return True
        except requests.RequestException:
            pass
        time.sleep(HEALTH_SLEEP)
    return False

def wait_http_ready_enhanced(url: str, server_type: str) -> bool:
    """å¢å¼·çš„å¥åº·æª¢æŸ¥ï¼Œé‡å°ä¸åŒæœå‹™å™¨é¡å‹èª¿æ•´ç­–ç•¥"""
    # ç‰¹å®šé¡å‹çµ¦æ›´é•·ç­‰å¾…
    max_retries = 45 if server_type in ['lighttpd', 'openlitespeed', 'tomcat'] else 30
    
    for attempt in range(max_retries):
        try:
            r = requests.get(url, timeout=5, headers=UA)
            # å¯¬é¬†æ¢ä»¶ï¼š<500 è¦–ç‚ºå¯æ¸¬ï¼›å° lighttpd å…è¨± 403/404 ä½œç‚ºå°±ç·’
            if r.status_code < 500 or (server_type == 'lighttpd' and r.status_code in [403, 404]):
                return True
        except requests.RequestException:
            pass
        
        # é¡¯ç¤ºé•·æ™‚é–“ç­‰å¾…çš„é€²åº¦
        if (attempt + 1) % 10 == 0:
            print(f'      â³ {server_type} å¥åº·æª¢æŸ¥ä¸­... ({attempt + 1}/{max_retries})')
            
        time.sleep(2)
    return False

def docker_run_with_fallback(image: str, name: str, host_port: int, server_type: str) -> tuple[bool, str]:
    """
    å˜—è©¦å•Ÿå‹•å®¹å™¨ï¼šå…ˆç”¨ primary imageï¼Œå†é€ä¸€å˜—è©¦ fallback imagesï¼›
    å°æ–¼å…§éƒ¨åŸ ï¼ŒåŒæ­¥å˜—è©¦å¸¸è¦‹é¸é …ï¼ˆtomcat:8080å„ªå…ˆï¼Œå…¶é¤˜:80â†’8080ï¼‰ã€‚
    å›å‚³ (æˆåŠŸ/å¤±æ•—, å¯¦éš›ä½¿ç”¨çš„æ˜ åƒ)
    """
    images_to_try = [image] + FALLBACK_IMAGES.get(server_type, [])
    internal_port_candidates = [8080, 80] if server_type == 'tomcat' else [80, 8080]

    for attempt_image in images_to_try:
        # é æ‹‰ä¸€æ¬¡ï¼Œé¿å… run æ™‚å¡åœ¨æ‹‰å–
        try:
            subprocess.run(['docker', 'pull', attempt_image], capture_output=True, text=True, timeout=120)
        except Exception:
            pass

        for internal_port in internal_port_candidates:
            # å…ˆæ¸…ç†æ®˜ç•™åŒåå®¹å™¨
            docker_stop(name)
            if docker_run(attempt_image, name, host_port, internal_port):
                return True, attempt_image

    return False, image

def extract_server(headers: dict, body: str, status_code: int = 200, expected_layer: str = 'L3') -> str:
    """
    æ ¹æ®è®ºæ–‡çš„9ç§ä¼ºæœå™¨ç±»å‹è¿›è¡ŒæŒ‡çº¹è¯†åˆ«
    é‡ç‚¹å…³æ³¨L3å±‚ï¼šTomcat, Flask, Express
    """
    server = headers.get('server', '').lower()
    body_l = body.lower() if isinstance(body, str) else ''
    
    # L3å±‚è¯†åˆ«ï¼ˆè®ºæ–‡é‡ç‚¹ï¼‰
    if expected_layer == 'L3':
        # Tomcat è¯†åˆ«
        tomcat_indicators = [
            'tomcat' in server,
            'catalina' in server,
            'coyote' in server,
            'apache tomcat' in body_l,
            'catalina' in body_l,
            'tomcat/' in body_l,
            status_code == 404 and 'status report' in body_l and 'tomcat' in body_l,
            '/manager' in body_l,
            'java.lang' in body_l,
            'servlet' in body_l and 'nginx' not in server and 'apache' not in server
        ]
        if any(tomcat_indicators):
            return 'tomcat'
            
        # Flask è¯†åˆ«
        flask_indicators = [
            'flask' in server,
            'werkzeug' in server,
            'flask application server' in body_l,
            'python/flask' in body_l,
            'werkzeug' in body_l and 'python' in body_l
        ]
        if any(flask_indicators):
            return 'flask'
            
        # Express è¯†åˆ« 
        express_indicators = [
            'express' in server,
            'node' in server and 'express' in body_l,
            'express application server' in body_l,
            'node.js/express' in body_l,
            'cannot get' in body_l and 'express' in body_l
        ]
        if any(express_indicators):
            return 'express'
    
    # L2å±‚è¯†åˆ«
    elif expected_layer == 'L2':
        if 'varnish' in server:
            return 'varnish_l2'
        if 'squid' in server or 'proxy' in server:
            return 'squid_l2'  
        if ('apache' in server or 'httpd' in server) and 'proxy' in body_l:
            return 'apache_l2'
    
    # L1å±‚è¯†åˆ«
    elif expected_layer == 'L1':
        if 'nginx' in server:
            return 'nginx_l1'
        if 'haproxy' in server:
            return 'haproxy_l1'
        if 'traefik' in server:
            return 'traefik_l1'
    
    # é€šç”¨å›é€€è¯†åˆ«ï¼ˆåŸºäºbase_nameï¼‰
    for server_type in ['tomcat', 'flask', 'express', 'varnish', 'squid', 'nginx', 'apache', 'haproxy', 'traefik']:
        if server_type in server or server_type in body_l:
            return server_type
    
    return 'unknown'

def calculate_realistic_accuracy(all_results, targets):
    """è¨ˆç®—æ›´çœŸå¯¦çš„æº–ç¢ºç‡ï¼ŒåŒ…å«å¤±æ•—æ¨£æœ¬"""
    
    # æŒ‰æœå‹™å™¨é¡å‹åˆ†çµ„
    server_stats = defaultdict(lambda: {'total': 0, 'correct': 0, 'failed': 0})
    
    for target in targets:
        expected_server = target.get('expected_l3', target.get('L3', '')).lower()
        server_stats[expected_server]['total'] += 1
        
        # å°‹æ‰¾å°æ‡‰çµæœ
        result = next((r for r in all_results if r['combo_id'] == target['combo_id']), None)
        
        if result and result.get('status') == 'ok' and result.get('is_correct'):
            server_stats[expected_server]['correct'] += 1
        else:
            server_stats[expected_server]['failed'] += 1
    
    # è¨ˆç®—æ•´é«”æº–ç¢ºç‡ï¼ˆåŸºæ–¼æ‰€æœ‰ç›®æ¨™ï¼Œä¸åªæˆåŠŸçš„ï¼‰
    total_targets = len(targets)
    total_correct = sum(stats['correct'] for stats in server_stats.values())
    realistic_accuracy = total_correct / total_targets if total_targets > 0 else 0
    
    return realistic_accuracy, server_stats

def run_batch(batch_targets):
    """åŸ·è¡Œä¸€æ‰¹å®¹å™¨æ¸¬è©¦"""
    started_containers = []
    results = []

    # æ–°å¢ï¼šæ‰¹å‰é æ‹‰æ˜ åƒ
    pre_pull_images(batch_targets)
    
    print(f'  å•Ÿå‹• {len(batch_targets)} å€‹å®¹å™¨...')
    
    # å•Ÿå‹•å®¹å™¨
    for t in batch_targets:
        combo_id = t['combo_id']
        l3_type = t.get('expected_l3', t.get('L3', 'nginx')).lower()
        host_port = get_host_port_from_url(t['url'])
        
        # é¸æ“‡æ˜ åƒ
        image = IMAGE_MAP.get(l3_type, 'nginx:alpine')
        container_name = f'baseline_{combo_id}'
        
        # ä½¿ç”¨å‚™é¸æ–¹æ¡ˆå˜—è©¦å•Ÿå‹•
        success, used_image = docker_run_with_fallback(image, container_name, host_port, l3_type)
        
        if success:
            started_containers.append({
                'name': container_name,
                'target': t,
                'port': host_port,
                'image': used_image,  # è¨˜éŒ„å¯¦éš›ä½¿ç”¨çš„æ˜ åƒ
                'server_type': l3_type  # è¨˜éŒ„æœå‹™å™¨é¡å‹ç”¨æ–¼ç­‰å¾…æ™‚é–“èª¿æ•´
            })
            print(f'    âœ… {combo_id}: {used_image} -> localhost:{host_port}')
        else:
            print(f'    âŒ {combo_id}: æ‰€æœ‰æ˜ åƒéƒ½å•Ÿå‹•å¤±æ•—')
            attempted_images = [image]
            if l3_type in FALLBACK_IMAGES:
                attempted_images.extend(FALLBACK_IMAGES[l3_type])
            results.append({
                'combo_id': combo_id,
                'url': t['url'],
                'expected_l3': t.get('expected_l3', t.get('L3')),
                'predicted_l3': 'unknown',
                'status': 'start_failed',
                'attempted_images': attempted_images
            })
    
    # ç­‰å¾…æœå‹™å°±ç·’ï¼ˆæ ¹æ“šæœå‹™å™¨é¡å‹èª¿æ•´ç­‰å¾…æ™‚é–“ï¼‰
    print(f'  ç­‰å¾… {len(started_containers)} å€‹æœå‹™å°±ç·’...')
    for container in started_containers:
        url = f"http://localhost:{container['port']}"
        server_type = container.get('server_type', 'default')
        ready = wait_http_ready_enhanced(url, server_type)
        container['ready'] = ready
        if ready:
            print(f'    âœ… {container["target"]["combo_id"]}: æœå‹™å°±ç·’')
        else:
            print(f'    âš ï¸ {container["target"]["combo_id"]}: æœå‹™æœªå°±ç·’')
    
    # åŸ·è¡ŒæŒ‡ç´‹æ¸¬è©¦
    print(f'  åŸ·è¡ŒæŒ‡ç´‹è­˜åˆ¥æ¸¬è©¦...')
    for container in started_containers:
        t = container['target']
        url = f"http://localhost:{container['port']}"
        
        if not container.get('ready'):
            results.append({
                'combo_id': t['combo_id'],
                'url': url,
                'expected_l3': t.get('expected_l3', t.get('L3')),
                'predicted_l3': 'unknown',
                'status': 'not_ready'
            })
            # æ–°å¢ï¼šä¸å°±ç·’ç«‹å³æ¸…ç†ï¼Œé¿å…ä½”åŸ é˜»å¡å¾ŒçºŒæ‰¹æ¬¡
            docker_stop(container['name'])
            continue
        
        try:
            r = requests.get(url, timeout=HTTP_TIMEOUT, headers=UA, allow_redirects=True)
            # ä»ç›®æ ‡ä¿¡æ¯ä¸­è·å–æœŸæœ›çš„å±‚çº§ï¼ˆé»˜è®¤ä¸ºL3ï¼‰
            expected_layer = 'L3'  # è®ºæ–‡é‡ç‚¹å…³æ³¨L3å±‚
            predicted = extract_server(
                {k.lower():v for k,v in r.headers.items()}, 
                r.text,
                r.status_code,
                expected_layer
            )
            
            results.append({
                'combo_id': t['combo_id'],
                'url': url,
                'expected_l3': t.get('expected_l3', t.get('L3')),
                'predicted_l3': predicted,
                'status': 'ok',
                'server_header': r.headers.get('Server', 'N/A'),
                'status_code': r.status_code,
                'is_correct': predicted.lower() == t.get('expected_l3', t.get('L3', '')).lower()
            })
            
            status = 'âœ…' if predicted.lower() == t.get('expected_l3', t.get('L3', '')).lower() else 'âŒ'
            print(f'    {status} {t["combo_id"]}: é æœŸ={t.get("expected_l3", t.get("L3"))}, è­˜åˆ¥={predicted}')
            
        except requests.RequestException as e:
            results.append({
                'combo_id': t['combo_id'],
                'url': url,
                'expected_l3': t.get('expected_l3', t.get('L3')),
                'predicted_l3': 'unknown',
                'status': 'request_failed',
                'error': str(e)
            })
            print(f'    âŒ {t["combo_id"]}: è«‹æ±‚å¤±æ•— - {e}')
    
    # æ¸…ç†å®¹å™¨ï¼ˆå¸¶é‡è©¦ï¼‰
    print(f'  æ¸…ç† {len(started_containers)} å€‹å®¹å™¨...')
    for container in started_containers:
        docker_stop(container['name'])
        # print(f'    ğŸ—‘ï¸ {container["target"]["combo_id"]}: å·²æ¸…ç†')  # æ¸›å°‘è¼¸å‡º
    print(f'  âœ… æ‰€æœ‰å®¹å™¨å·²æ¸…ç†')
    
    return results

def main():
    print('ğŸ§ª æ‰¹æ¬¡ Untangle åŸºç·šæ¸¬è©¦ï¼ˆ10/æ‰¹ï¼Œå«æ¸…ç†ï¼‰')
    print('=' * 50)
    
    try:
        targets = load_targets()
        print(f'ğŸ“Š è¼‰å…¥ {len(targets)} å€‹æ¸¬è©¦ç›®æ¨™')
    except FileNotFoundError as e:
        print(f'âŒ {e}')
        return 1
    
    if not targets:
        print('âŒ ç„¡æ¸¬è©¦ç›®æ¨™')
        return 1
    
    # æª¢æŸ¥ Docker æ˜¯å¦å¯ç”¨
    try:
        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print('âŒ Docker ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª Docker å·²å®‰è£ä¸¦å•Ÿå‹•')
            return 1
        print(f'âœ… Docker å·²å°±ç·’: {result.stdout.strip()}')
    except Exception:
        print('âŒ æ‰¾ä¸åˆ° Docker å‘½ä»¤')
        return 1
    
    all_results = []
    total = len(targets)
    batches = math.ceil(total / BATCH_SIZE)
    
    for bi in range(batches):
        batch_start = bi * BATCH_SIZE
        batch_end = min((bi + 1) * BATCH_SIZE, total)
        batch_targets = targets[batch_start:batch_end]
        
        print(f'\nğŸ“¦ æ‰¹æ¬¡ {bi+1}/{batches} ({len(batch_targets)} å€‹ç›®æ¨™)')
        batch_results = run_batch(batch_targets)
        all_results.extend(batch_results)
        
            # æ‰¹æ¬¡é–“ç¨å¾®æš«åœï¼Œç¢ºä¿å®¹å™¨å®Œå…¨æ¸…ç†
        if bi < batches - 1:
            print('  â³ æ‰¹æ¬¡é–“æš«åœ 3 ç§’...')
            time.sleep(3)
    
    # æ”¶é›†å¤±æ•—æ¨£æœ¬é€²è¡Œé‡è©¦
    failed_targets = []
    for result in all_results:
        if result.get('status') in ['start_failed', 'not_ready']:
            # å¾åŸå§‹ targets ä¸­æ‰¾å›å®Œæ•´ä¿¡æ¯
            original_target = next(
                (t for t in targets if t['combo_id'] == result['combo_id']), None
            )
            if original_target:
                failed_targets.append(original_target)

    # å°å¤±æ•—æ¨£æœ¬é€²è¡Œä¸€æ¬¡é‡è©¦
    if failed_targets and len(failed_targets) <= 50:  # é¿å…é‡è©¦éå¤š
        print(f'\nğŸ” å° {len(failed_targets)} å€‹å¤±æ•—æ¨£æœ¬é€²è¡Œé‡è©¦...')
        
        # åˆ†æ‰¹é‡è©¦
        retry_batches = math.ceil(len(failed_targets) / BATCH_SIZE)
        for bi in range(retry_batches):
            batch_start = bi * BATCH_SIZE
            batch_end = min((bi + 1) * BATCH_SIZE, len(failed_targets))
            retry_batch = failed_targets[batch_start:batch_end]
            
            print(f'  é‡è©¦æ‰¹æ¬¡ {bi+1}/{retry_batches} ({len(retry_batch)} å€‹ç›®æ¨™)')
            retry_results = run_batch(retry_batch)
            
            # æ›¿æ›åŸçµæœä¸­çš„å¤±æ•—é …
            for retry_result in retry_results:
                if retry_result.get('status') == 'ok':
                    # æ‰¾åˆ°ä¸¦æ›¿æ›åŸä¾†çš„å¤±æ•—çµæœ
                    for i, orig_result in enumerate(all_results):
                        if orig_result['combo_id'] == retry_result['combo_id']:
                            all_results[i] = retry_result
                            print(f'    âœ… {retry_result["combo_id"]}: é‡è©¦æˆåŠŸï¼')
                            break
            
            # é‡è©¦æ‰¹æ¬¡é–“æš«åœ
            if bi < retry_batches - 1:
                print('  â³ é‡è©¦æ‰¹æ¬¡é–“æš«åœ 3 ç§’...')
                time.sleep(3)
    elif len(failed_targets) > 50:
        print(f'\nâš ï¸ å¤±æ•—æ¨£æœ¬éå¤š ({len(failed_targets)} å€‹)ï¼Œè·³éé‡è©¦')
    
    # çµ±è¨ˆçµæœ
    total_tested = len([r for r in all_results if r.get('status') == 'ok'])
    total_correct = len([r for r in all_results if r.get('is_correct')])
    accuracy = (total_correct / total_tested) if total_tested > 0 else 0.0
    
    # æ–°å¢ï¼šçœŸå¯¦æ•´é«”æº–ç¢ºç‡ï¼ˆåˆ†æ¯=å…¨éƒ¨ç›®æ¨™ï¼‰
    total_targets = total
    true_correct = sum(1 for r in all_results if r.get('status') == 'ok' and r.get('is_correct'))
    realistic_accuracy_overall = true_correct / total_targets if total_targets > 0 else 0.0
    
    status_counts = Counter(r['status'] for r in all_results)
    
    # å„æœå‹™å™¨é¡å‹æº–ç¢ºç‡ï¼ˆåƒ…æˆåŠŸæ¨£æœ¬ï¼‰
    server_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
    for r in all_results:
        if r.get('status') == 'ok':
            expected = r['expected_l3'].lower()
            server_stats[expected]['total'] += 1
            if r.get('is_correct'):
                server_stats[expected]['correct'] += 1
    
    # è¨ˆç®—çœŸå¯¦æº–ç¢ºç‡ï¼ˆåŒ…å«å¤±æ•—æ¨£æœ¬ï¼‰
    realistic_accuracy, realistic_server_stats = calculate_realistic_accuracy(all_results, targets)
    
    # è¼¸å‡ºçµæœ
    print('\n' + '=' * 50)
    print('ğŸ“ˆ æ‰¹æ¬¡åŸºç·šæ¸¬è©¦çµæœ')
    print('=' * 50)
    print(f'ç¸½æ¸¬è©¦ç›®æ¨™: {total}')
    print(f'æˆåŠŸæ¸¬è©¦: {total_tested}')
    print(f'æ­£ç¢ºè­˜åˆ¥(æˆåŠŸä¸­çš„): {total_correct}')
    print(f'L3 æˆåŠŸæ¨£æœ¬æº–ç¢ºç‡: {accuracy:.1%}')
    print(f'L3 çœŸå¯¦æ•´é«”æº–ç¢ºç‡: {realistic_accuracy_overall:.1%}ï¼ˆåˆ†æ¯=å…¨éƒ¨ç›®æ¨™ï¼‰')
    print(f'ç‹€æ…‹åˆ†å¸ƒ: {dict(status_counts)}')
    
    if realistic_server_stats:
        print(f'\nğŸ“Š çœŸå¯¦å„ L3 æœå‹™å™¨æº–ç¢ºç‡ï¼ˆåŒ…å«å•Ÿå‹•å¤±æ•—ï¼‰:')
        for server, stats in sorted(realistic_server_stats.items()):
            real_acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
            print(f'  {server:12}: {real_acc:6.1%} ({stats["correct"]:2d}/{stats["total"]:2d}) [å¤±æ•—: {stats["failed"]}]')
    
    if server_stats:
        print(f'\nğŸ“Š æˆåŠŸæ¨£æœ¬å„ L3 æœå‹™å™¨æº–ç¢ºç‡ï¼ˆåƒ…å°±ç·’æœå‹™ï¼‰:')
        for server, stats in sorted(server_stats.items()):
            acc = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
            print(f'  {server:12}: {acc:6.1%} ({stats["correct"]:2d}/{stats["total"]:2d})')
    
    # è«–æ–‡é æœŸå°ç…§ï¼ˆä½¿ç”¨çœŸå¯¦æº–ç¢ºç‡ï¼‰
    expected_range = (0.50, 0.55)
    if expected_range[0] <= realistic_accuracy <= expected_range[1]:
        status = 'âœ… ç¬¦åˆè«–æ–‡é æœŸ'
    elif realistic_accuracy < expected_range[0]:
        status = 'âš ï¸ ä½æ–¼é æœŸç¯„åœ'
    else:
        status = 'ğŸ“ˆ é«˜æ–¼é æœŸç¯„åœ'
    
    print(f'\nğŸ¯ è«–æ–‡é æœŸç¯„åœ: {expected_range[0]*100:.0f}-{expected_range[1]*100:.0f}% | çœŸå¯¦çµæœ: {realistic_accuracy:.1%} {status}')
    
    # ä¿å­˜çµæœ
    output = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'method': 'Untangle Baseline (Batched with Cleanup)',
        'test_summary': {
            'total_targets': total,
            'successful_tests': total_tested,
            'failed_tests': total - total_tested,
            'correct_predictions': total_correct,
            'realistic_accuracy': realistic_accuracy,  # åŒ…å«å¤±æ•—æ¨£æœ¬çš„çœŸå¯¦æº–ç¢ºç‡
            'success_only_accuracy': accuracy,  # åƒ…æˆåŠŸæ¨£æœ¬çš„æº–ç¢ºç‡
            'status_distribution': dict(status_counts),
            'error_rate': (total - total_tested) / total if total > 0 else 0
        },
        'realistic_server_accuracy': {k: {'accuracy': v['correct']/v['total'] if v['total']>0 else 0, **v} 
                                     for k, v in realistic_server_stats.items()},
        'server_accuracy': {k: {'accuracy': v['correct']/v['total'] if v['total']>0 else 0, **v} 
                           for k, v in server_stats.items()},
        'detailed_results': all_results
    }
    
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    output_file = RESULTS_DIR / f'untangle_batched_results_{int(time.time())}.json'
    output_file.write_text(json.dumps(output, indent=2, ensure_ascii=False), encoding='utf-8')
    
    print(f'\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜: {output_file}')
    print('âœ… å¯ç”¨æ–¼ BCa Bootstrap çµ±è¨ˆåˆ†æ')
    
    # åˆ¤æ–·æˆåŠŸæ¨™æº–ï¼ˆä½¿ç”¨çœŸå¯¦æº–ç¢ºç‡ï¼‰
    if realistic_accuracy >= 0.40:  # å…è¨±åˆç†ç¯„åœï¼ˆè€ƒæ…®å¤±æ•—æ¨£æœ¬å¾Œçš„æ¨™æº–ï¼‰
        print('ğŸ‰ åŸºç·šæ¸¬è©¦å®Œæˆï¼ŒçœŸå¯¦æº–ç¢ºç‡åœ¨åˆç†ç¯„åœå…§')
        return 0
    else:
        print('âš ï¸ åŸºç·šæ¸¬è©¦å®Œæˆï¼Œä½†çœŸå¯¦æº–ç¢ºç‡åä½ï¼Œè«‹æª¢æŸ¥é…ç½®')
        return 0  # ä»è¿”å› 0ï¼Œå› ç‚ºæ¸¬è©¦æµç¨‹æˆåŠŸ

if __name__ == '__main__':
    sys.exit(main())