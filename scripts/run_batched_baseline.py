#!/usr/bin/env python3
"""
æ‰¹æ¬¡ Untangle åŸºç·šæ¸¬è©¦ï¼ˆä¿®æ­£ç‰ˆï¼‰
- æ”¹ç‚ºç›´æ¥å¾ data/combinations.json è¼‰å…¥æ‰€æœ‰çµ„åˆä½œç‚ºæ¸¬è©¦ç›®æ¨™
- è‹¥å­˜åœ¨ results/baseline_targets.jsonï¼Œåƒ…ä½œç‚ºè¦†è“‹æ¸…å–®ï¼ˆå„ªå…ˆï¼‰ï¼Œå¦å‰‡ä½¿ç”¨å…¨é‡ 90 çµ„
- æ”¯æ´ --limit èˆ‡ --offset åƒæ•¸åˆ†æ®µåŸ·è¡Œï¼›é è¨­è·‘å…¨é‡
- æ‰¹æ¬¡å¤§å°ä»ç‚º 10ï¼Œæœƒè‡ªå‹•è¨ˆç®—æ‰¹æ•¸
"""
import json, time, re, requests, math, subprocess, sys, argparse
from pathlib import Path
from collections import defaultdict, Counter

ROOT = Path(__file__).resolve().parents[1]
RESULTS_DIR = ROOT / 'results'
TARGETS_PATH = RESULTS_DIR / 'baseline_targets.json'
COMBO_PATH = ROOT / 'data' / 'combinations.json'
BATCH_SIZE = 10
HTTP_TIMEOUT = 8
HEALTH_RETRIES = 15
HEALTH_SLEEP = 1.5

IMAGE_MAP = {
    'apache': 'httpd:2.4-alpine',
    'nginx': 'nginx:alpine', 
    'caddy': 'caddy:alpine',
    'lighttpd': 'sebp/lighttpd:latest',
    'tomcat': 'tomcat:10.1-jdk17',
    'openlitespeed': 'httpd:2.4-alpine'
}

FALLBACK_IMAGES = {
    'openlitespeed': ['litespeedtech/openlitespeed:1.7-lsphp81', 'httpd:2.4-alpine', 'nginx:alpine'],
    'lighttpd': ['sebp/lighttpd:1.4', 'httpd:2.4-alpine']
}

INTERNAL_PORT_MAP = {
    'tomcat': 8080,
    'openlitespeed': 8088,
    'default': 80
}

STARTUP_WAIT_MAP = {
    'tomcat': 15,
    'openlitespeed': 10,
    'lighttpd': 5,
    'default': 3
}

UA = {'User-Agent': 'Untangle-Fingerprinter/1.0'}

def load_all_combinations():
    if not COMBO_PATH.exists():
        raise FileNotFoundError(f'æ‰¾ä¸åˆ° {COMBO_PATH}ï¼Œè«‹å…ˆåŸ·è¡Œ: python scripts/generate_sets.py')
    return json.loads(COMBO_PATH.read_text(encoding='utf-8'))

def load_targets_from_results():
    if TARGETS_PATH.exists():
        data = json.loads(TARGETS_PATH.read_text(encoding='utf-8'))
        return data.get('targets', [])
    return []

def build_targets(limit=None, offset=0):
    override = load_targets_from_results()
    if override:
        return override[offset:(offset+limit) if limit else None]
    combos = load_all_combinations()
    targets = []
    for c in combos:
        l3_base = c['l3'].get('base_name') or c['l3']['name'].split('_')[0]
        targets.append({
            'combo_id': c['id'],
            'url': c['url'],
            'expected_l3': l3_base
        })
    return targets[offset:(offset+limit) if limit else None]

def get_host_port_from_url(url: str) -> int:
    m = re.search(r':(\d+)$', url.strip())
    if not m:
        raise ValueError(f'URL ç„¡æ³•è§£æåŸ : {url}')
    return int(m.group(1))

def docker_run(image: str, name: str, host_port: int, internal_port: int = 80, max_retries: int = 2) -> bool:
    for attempt in range(max_retries):
        try:
            subprocess.run(['docker', 'rm', '-f', name], capture_output=True, check=False)
            cmd = ['docker','run','-d','--rm','--name',name,'-p',f'{host_port}:{internal_port}','--label','project=llm-untangle','--label','type=baseline',image]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                return True
            if attempt < max_retries - 1:
                time.sleep(2)
        except Exception:
            if attempt == max_retries - 1:
                return False
            time.sleep(2)
    return False

def docker_stop(name: str, max_retries: int = 2):
    for attempt in range(max_retries):
        try:
            subprocess.run(['docker','stop',name], capture_output=True, timeout=10, check=False)
            subprocess.run(['docker','rm','-f',name], capture_output=True, timeout=10, check=False)
            return
        except Exception:
            if attempt < max_retries - 1:
                time.sleep(1)


def wait_http_ready_enhanced(url: str, server_type: str) -> bool:
    max_retries = 45 if server_type == 'lighttpd' else 30
    for attempt in range(max_retries):
        try:
            r = requests.get(url, timeout=5)
            if r.status_code < 500 or (server_type == 'lighttpd' and r.status_code in [403,404]):
                return True
        except requests.RequestException:
            pass
        if server_type in ['lighttpd','openlitespeed'] and (attempt+1) % 10 == 0:
            print(f'      â³ {server_type} å¥åº·æª¢æŸ¥ä¸­... ({attempt+1}/{max_retries})')
        time.sleep(2)
    return False

def docker_run_with_fallback(image: str, name: str, host_port: int, server_type: str) -> tuple:
    images_to_try = [image]
    if server_type in FALLBACK_IMAGES:
        images_to_try.extend(FALLBACK_IMAGES[server_type])
    internal_ports = [8080,80] if server_type=='tomcat' else [80,8080]
    for attempt_image in images_to_try:
        subprocess.run(['docker','pull',attempt_image], capture_output=True, text=True, timeout=60)
        for p in internal_ports:
            if docker_run(attempt_image, name, host_port, p):
                return True, attempt_image
            docker_stop(name)
    return False, image

def extract_server(headers: dict, body: str, status_code: int = 200) -> str:
    server = headers.get('server','').lower()
    body_l = body.lower() if isinstance(body,str) else ''
    tomcat_indicators = ['apache tomcat' in body_l,'catalina' in body_l,'tomcat/' in body_l,status_code==404 and 'status report' in body_l,status_code==404 and 'type status report' in body_l,'http status 404' in body_l and 'apache' not in server and 'nginx' not in server,'/manager' in body_l,'java.lang' in body_l,'servlet' in body_l and 'nginx' not in server and 'apache' not in server]
    if any(tomcat_indicators):
        if 'apache' not in server and 'nginx' not in server and 'httpd' not in server:
            return 'tomcat'
    litespeed_indicators = ['litespeed' in server,'openlitespeed' in server,'lsws' in server,'litespeed' in body_l,('x-powered-by' in headers and 'litespeed' in headers.get('x-powered-by','').lower())]
    if any(litespeed_indicators):
        return 'openlitespeed'
    if 'lighttpd' in server or 'lighttpd' in body_l:
        return 'lighttpd'
    server_patterns = {'nginx':['nginx'],'apache':['apache','httpd'],'caddy':['caddy'],'tomcat':['tomcat','coyote']}
    for server_type, patterns in server_patterns.items():
        for pattern in patterns:
            if pattern in server:
                return server_type
    if 'nginx' in body_l:
        return 'nginx'
    if 'caddy' in body_l:
        return 'caddy'
    if 'apache' in body_l and 'tomcat' not in body_l:
        return 'apache'
    return 'unknown'


def calculate_realistic_accuracy(all_results, targets):
    server_stats = defaultdict(lambda: {'total':0,'correct':0,'failed':0})
    for t in targets:
        expected = t.get('expected_l3', t.get('L3','')).lower()
        server_stats[expected]['total'] += 1
        result = next((r for r in all_results if r['combo_id']==t['combo_id']), None)
        if result and result.get('status')=='ok' and result.get('is_correct'):
            server_stats[expected]['correct'] += 1
        else:
            server_stats[expected]['failed'] += 1
    total = len(targets)
    total_correct = sum(s['correct'] for s in server_stats.values())
    realistic = total_correct/total if total>0 else 0
    return realistic, server_stats


def run_batch(batch_targets):
    started_containers = []
    results = []
    print(f'  å•Ÿå‹• {len(batch_targets)} å€‹å®¹å™¨...')
    for t in batch_targets:
        combo_id = t['combo_id']
        l3_type = t.get('expected_l3', t.get('L3','nginx')).lower()
        host_port = get_host_port_from_url(t['url'])
        image = IMAGE_MAP.get(l3_type, 'nginx:alpine')
        name = f'baseline_{combo_id}'
        success, used_image = docker_run_with_fallback(image, name, host_port, l3_type)
        if success:
            started_containers.append({'name':name,'target':t,'port':host_port,'image':used_image,'server_type':l3_type})
            print(f'    âœ… {combo_id}: {used_image} -> localhost:{host_port}')
        else:
            results.append({'combo_id':combo_id,'url':t['url'],'expected_l3':t.get('expected_l3',t.get('L3')),'predicted_l3':'unknown','status':'start_failed'})
    print(f'  ç­‰å¾… {len(started_containers)} å€‹æœå‹™å°±ç·’...')
    for c in started_containers:
        url = f"http://localhost:{c['port']}"
        ready = wait_http_ready_enhanced(url, c.get('server_type','default'))
        c['ready'] = ready
        print(f"    {'âœ…' if ready else 'âš ï¸'} {c['target']['combo_id']}: {'æœå‹™å°±ç·’' if ready else 'æœå‹™æœªå°±ç·’'}")
    print(f'  åŸ·è¡ŒæŒ‡ç´‹è­˜åˆ¥æ¸¬è©¦...')
    for c in started_containers:
        t = c['target']
        url = f"http://localhost:{c['port']}"
        if not c.get('ready'):
            results.append({'combo_id':t['combo_id'],'url':url,'expected_l3':t.get('expected_l3',t.get('L3')),'predicted_l3':'unknown','status':'not_ready'})
            continue
        try:
            r = requests.get(url, timeout=HTTP_TIMEOUT, headers=UA, allow_redirects=True)
            predicted = extract_server({k.lower():v for k,v in r.headers.items()}, r.text, r.status_code)
            results.append({'combo_id':t['combo_id'],'url':url,'expected_l3':t.get('expected_l3',t.get('L3')),'predicted_l3':predicted,'status':'ok','server_header':r.headers.get('Server','N/A'),'status_code':r.status_code,'is_correct':predicted.lower()==t.get('expected_l3',t.get('L3','')).lower()})
            print(f"    {'âœ…' if predicted.lower()==t.get('expected_l3',t.get('L3','')).lower() else 'âŒ'} {t['combo_id']}: é æœŸ={t.get('expected_l3',t.get('L3'))}, è­˜åˆ¥={predicted}")
        except requests.RequestException as e:
            results.append({'combo_id':t['combo_id'],'url':url,'expected_l3':t.get('expected_l3',t.get('L3')),'predicted_l3':'unknown','status':'request_failed','error':str(e)})
            print(f'    âŒ {t["combo_id"]}: è«‹æ±‚å¤±æ•— - {e}')
    print(f'  æ¸…ç† {len(started_containers)} å€‹å®¹å™¨...')
    for c in started_containers:
        docker_stop(c['name'])
    print('  âœ… æ‰€æœ‰å®¹å™¨å·²æ¸…ç†')
    return results


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--limit', type=int, default=None, help='é™åˆ¶æ¸¬è©¦çš„ç›®æ¨™æ•¸é‡')
    parser.add_argument('--offset', type=int, default=0, help='å¾ç¬¬å¹¾å€‹ç›®æ¨™é–‹å§‹')
    args = parser.parse_args()

    print('ğŸ§ª æ‰¹æ¬¡ Untangle åŸºç·šæ¸¬è©¦ï¼ˆ10/æ‰¹ï¼Œå«æ¸…ç†ï¼‰')
    print('=' * 50)

    try:
        targets = build_targets(limit=args.limit, offset=args.offset)
        print(f'ğŸ“Š è¼‰å…¥ {len(targets)} å€‹æ¸¬è©¦ç›®æ¨™')
    except FileNotFoundError as e:
        print(f'âŒ {e}')
        return 1

    if not targets:
        print('âŒ ç„¡æ¸¬è©¦ç›®æ¨™')
        return 1

    try:
        result = subprocess.run(['docker','--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print('âŒ Docker ä¸å¯ç”¨ï¼Œè«‹ç¢ºèª Docker å·²å®‰è£ä¸¦å•Ÿå‹•')
            return 1
        print(f'âœ… Docker å·²å°±ç·’: {result.stdout.strip()}')
    except Exception:
        print('âŒ æ‰¾ä¸åˆ° Docker å‘½ä»¤')
        return 1

    all_results = []
    total = len(targets)
    batches = math.ceil(total / BATCH_SIZE)

    for bi in range(batches):
        batch_start = bi * BATCH_SIZE
        batch_end = min((bi + 1) * BATCH_SIZE, total)
        batch_targets = targets[batch_start:batch_end]
        print(f'\nğŸ“¦ æ‰¹æ¬¡ {bi+1}/{batches} ({len(batch_targets)} å€‹ç›®æ¨™)')
        batch_results = run_batch(batch_targets)
        all_results.extend(batch_results)
        if bi < batches - 1:
            print('  â³ æ‰¹æ¬¡é–“æš«åœ 3 ç§’...')
            time.sleep(3)

    realistic_accuracy, realistic_server_stats = calculate_realistic_accuracy(all_results, targets)
    total_tested = len([r for r in all_results if r.get('status')=='ok'])
    total_correct = len([r for r in all_results if r.get('is_correct')])
    accuracy = (total_correct/total_tested) if total_tested>0 else 0.0
    status_counts = Counter(r['status'] for r in all_results)

    print('\n' + '='*50)
    print('ğŸ“ˆ æ‰¹æ¬¡åŸºç·šæ¸¬è©¦çµæœ')
    print('='*50)
    print(f'ç¸½æ¸¬è©¦ç›®æ¨™: {total}')
    print(f'æˆåŠŸæ¸¬è©¦: {total_tested}')
    print(f'æ­£ç¢ºè­˜åˆ¥: {total_correct}')
    print(f'L3 çœŸå¯¦æ•´é«”æº–ç¢ºç‡: {realistic_accuracy:.1%}ï¼ˆåŒ…å«å¤±æ•—æ¨£æœ¬ï¼‰')
    print(f'L3 æˆåŠŸæ¨£æœ¬æº–ç¢ºç‡: {accuracy:.1%}ï¼ˆåƒ…æˆåŠŸæ¨£æœ¬ï¼‰')
    print(f'ç‹€æ…‹åˆ†å¸ƒ: {dict(status_counts)}')

    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    output_file = RESULTS_DIR / f'untangle_batched_results_{int(time.time())}.json'
    output = {'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),'method':'Untangle Baseline (Batched with Cleanup)','total_targets':total,'success_only_accuracy':accuracy,'realistic_accuracy':realistic_accuracy,'status_distribution':dict(status_counts),'detailed_results':all_results}
    output_file.write_text(json.dumps(output, indent=2, ensure_ascii=False), encoding='utf-8')
    print(f'\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜: {output_file}')
    print('âœ… å¯ç”¨æ–¼ BCa Bootstrap çµ±è¨ˆåˆ†æ')
    return 0

if __name__ == '__main__':
    sys.exit(main())
